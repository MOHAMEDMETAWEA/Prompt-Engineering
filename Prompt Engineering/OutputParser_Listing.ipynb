{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d4c9ef",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b563e624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ENV variables: OrderedDict({'OPENAI_API_KEY': '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', 'OPENAI_API_BASE': 'https://openrouter.ai/api/v1', 'OPENAI_API_Name': 'gpt-4o'})\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Load environment variables\n",
    "# ==============================\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load variables from app.env\n",
    "env_vars = dotenv_values(\"app.env\")\n",
    "print(\"Loaded ENV variables:\", env_vars)\n",
    "\n",
    "# Extract required variables\n",
    "openai_api_key = env_vars[\"OPENAI_API_KEY\"]\n",
    "openai_api_base = env_vars.get(\"OPENAI_API_BASE\")\n",
    "openai_api_name = env_vars[\"OPENAI_API_Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c01f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Create LangChain Chat Model\n",
    "# ==============================\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=openai_api_name,\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    "    temperature=0.7,\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8eb8b3",
   "metadata": {},
   "source": [
    "# Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542130f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "The theory of relativity, developed by Albert Einstein, consists of two main parts: special relativity and general relativity. Here's a simplified explanation of each:\n",
      "\n",
      "1. **Special Relativity:** \n",
      "   - **Concept**: This part of the theory deals with the physics of objects moving at constant speeds, particularly those moving close to the speed of light.\n",
      "   - **Key Ideas**:\n",
      "     - **Speed of Light**: The speed of light is the same for all observers, no matter\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Send a prompt to the model\n",
    "# ==============================\n",
    "task = \"Explain the theory of relativity in simple terms.\"\n",
    "\n",
    "response = chat.invoke(task)\n",
    "\n",
    "print(\"\\nAI Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee192ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-1.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-openai) (2.11.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain_core-1.2.2-py3-none-any.whl (476 kB)\n",
      "Downloading langchain_openai-1.1.4-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: langchain-core, langchain-openai\n",
      "\n",
      "  Attempting uninstall: langchain-core\n",
      "\n",
      "    Found existing installation: langchain-core 1.2.1\n",
      "\n",
      "    Uninstalling langchain-core-1.2.1:\n",
      "\n",
      "      Successfully uninstalled langchain-core-1.2.1\n",
      "\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "  Attempting uninstall: langchain-openai\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "    Found existing installation: langchain-openai 1.1.3\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "    Uninstalling langchain-openai-1.1.3:\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "      Successfully uninstalled langchain-openai-1.1.3\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   ---------------------------------------- 2/2 [langchain-openai]\n",
      "\n",
      "Successfully installed langchain-core-1.2.2 langchain-openai-1.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/langchain/\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-core langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b0d05a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Format Instructions:\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "\n",
      "Generated Prompt:\n",
      "List 5 key concepts of the theory of relativity.\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "\n",
      "AI Response:\n",
      "Time dilation, length contraction, mass-energy equivalence, equivalence principle, spacetime curvature\n",
      "\n",
      "Parsed Output:\n",
      "['Time dilation', 'length contraction', 'mass-energy equivalence', 'equivalence principle', 'spacetime curvature']\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Output Parser Example \n",
    "# ==============================\n",
    "\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Create output parser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Get formatting instructions\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(\"\\nFormat Instructions:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# Create a prompt template using the parser\n",
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"List 5 key concepts of the {type}.\\n\"\n",
    "        \"{format_instructions}\"\n",
    "    ),\n",
    "    input_variables=[\"type\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions\n",
    "    }\n",
    ")\n",
    "\n",
    "# Format the prompt (provide the required 'type' variable)\n",
    "formatted_prompt = prompt.format(type=\"theory of relativity\")\n",
    "\n",
    "print(\"\\nGenerated Prompt:\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "# Send the formatted prompt to the chat model\n",
    "response = chat.invoke(formatted_prompt)\n",
    "print(\"\\nAI Response:\")\n",
    "print(response.content)\n",
    "\n",
    "# Parse the response using the output parser\n",
    "parsed_output = output_parser.parse(response.content)\n",
    "print(\"\\nParsed Output:\")\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1d9d4",
   "metadata": {},
   "source": [
    "# Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3502b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c2ac023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Formatted Prompt:\n",
      "When was Albert Einstein born?\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template = \"When was {person} born?\",\n",
    "    input_variables = [\"person\"]\n",
    ")   \n",
    "formatted_prompt = prompt.format(person=\"Albert Einstein\")\n",
    "print(\"\\nFormatted Prompt:\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d87b2428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Albert Einstein was born on March 14, 1879.\n"
     ]
    }
   ],
   "source": [
    "# Send the formatted prompt to the chat model\n",
    "response = chat.invoke(formatted_prompt)\n",
    "print(\"\\nAI Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cef23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Formatted Prompt:\n",
      "When was Albert Einstein born?\n",
      "Replay with a date in the format YYYY-MM-DD.\n"
     ]
    }
   ],
   "source": [
    "format_instructions = \"Replay with a date in the format YYYY-MM-DD.\" \n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"When was {person} born?\\n{format_instructions}\",\n",
    "    input_variables = [\"person\"],\n",
    "    partial_variables = {\n",
    "        \"format_instructions\": format_instructions\n",
    "    }\n",
    ")   \n",
    "formatted_prompt = prompt.format(person=\"Albert Einstein\")\n",
    "print(\"\\nFormatted Prompt:\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e089312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Albert Einstein was born on 1879-03-14.\n"
     ]
    }
   ],
   "source": [
    "# Send the formatted prompt to the chat model\n",
    "response = chat.invoke(formatted_prompt)\n",
    "print(\"\\nAI Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f119be",
   "metadata": {},
   "source": [
    "# PyDantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2001f",
   "metadata": {},
   "source": [
    "useful to order data as oop \n",
    "\n",
    "your output can be class with some properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba706a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\users\\administrator\\anaconda3\\lib\\site-packages (2.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83770d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plate_name': 'Shawerma',\n",
       " 'ingredients': ['Chicken', 'Garlic Sauce', 'Pickles', 'Pita Bread']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"plate_name\": \"Shawerma\",\n",
    "    \"ingredients\": \n",
    "    [\"Chicken\", \"Garlic Sauce\", \"Pickles\", \"Pita Bread\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6aadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Format Instructions:\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"plate_name\": {\"description\": \"The name of the dish or plate.\", \"title\": \"Plate Name\", \"type\": \"string\"}, \"ingredients\": {\"description\": \"The list of ingredients in the dish.\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}}, \"required\": [\"plate_name\", \"ingredients\"]}\n",
      "```\n",
      "\n",
      "Generated Prompt:\n",
      "Describe a popular dish called Shawerma.\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"plate_name\": {\"description\": \"The name of the dish or plate.\", \"title\": \"Plate Name\", \"type\": \"string\"}, \"ingredients\": {\"description\": \"The list of ingredients in the dish.\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}}, \"required\": [\"plate_name\", \"ingredients\"]}\n",
      "```\n",
      "\n",
      "AI Response:\n",
      "```json\n",
      "{\n",
      "  \"plate_name\": \"Shawerma\",\n",
      "  \"ingredients\": [\n",
      "    \"Marinated meat (usually chicken, beef, or lamb)\",\n",
      "    \"Pita bread or flatbread\",\n",
      "    \"Tahini sauce\",\n",
      "    \"Garlic sauce\",\n",
      "    \"Pickles\",\n",
      "    \"Tomatoes\",\n",
      "    \"Onions\",\n",
      "    \"Lettuce\",\n",
      "    \"Spices (such as cumin, paprika, and turmeric)\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel , Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# useful to order data as oop\n",
    "# must inherit from BaseModel\n",
    "\n",
    "class Plate(BaseModel):\n",
    "    plate_name : str = Field(\n",
    "        description=\"The name of the dish or plate.\"\n",
    "    )   \n",
    "    ingredients : list[str] = Field(\n",
    "        description=\"The list of ingredients in the dish.\"\n",
    "    )\n",
    "\n",
    "# Create Pydantic output parser\n",
    "output_parser = PydanticOutputParser(pydantic_object=Plate)\n",
    "\n",
    "# Get formatting instructions\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(\"\\nFormat Instructions:\")\n",
    "print(format_instructions)\n",
    "# Create a prompt template using the parser\n",
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Describe a popular dish called {dish}.\\n\"\n",
    "        \"{format_instructions}\"\n",
    "    ),\n",
    "    input_variables=[\"dish\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions\n",
    "    }\n",
    ")\n",
    "\n",
    "# Format the prompt (provide the required 'dish' variable)\n",
    "formatted_prompt = prompt.format(dish=\"Shawerma\")\n",
    "print(\"\\nGenerated Prompt:\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "# Send the formatted prompt to the chat model\n",
    "response = chat.invoke(formatted_prompt)\n",
    "print(\"\\nAI Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dcf0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed Output:\n",
      "plate_name='Shawerma' ingredients=['Marinated meat (usually chicken, beef, or lamb)', 'Pita bread or flatbread', 'Tahini sauce', 'Garlic sauce', 'Pickles', 'Tomatoes', 'Onions', 'Lettuce', 'Spices (such as cumin, paprika, and turmeric)']\n"
     ]
    }
   ],
   "source": [
    "responsed_parsed = output_parser.parse(response.content)\n",
    "print(\"\\nParsed Output:\")\n",
    "print(responsed_parsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
