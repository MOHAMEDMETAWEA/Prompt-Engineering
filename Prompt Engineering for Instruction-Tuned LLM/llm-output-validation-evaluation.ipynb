{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e1d97b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007396,
     "end_time": "2024-04-20T18:36:50.156464",
     "exception": false,
     "start_time": "2024-04-20T18:36:50.149068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">  Prompt Engineering Best Practices: LLM Output Validation & Evaluation </center>\n",
    "\n",
    "# <center style=\"font-family: consolas; font-size: 25px; font-weight: bold;\">  Validating Output from Instruction-Tuned LLMs </center>\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "Checking outputs before showing them to users can be important for ensuring the quality, relevance, and safety of the responses provided to them or used in automation flows.\n",
    "In this notebook, we will learn how to use the Moderation API by OpenAI to ensure safety and free of harassment output. \n",
    "\n",
    "Also, we will learn how to use additional prompts to the model to evaluate output quality before displaying them to the user to ensure the generated output follows the given instructions and is free of hallucinations.\n",
    "\n",
    "#### <a id=\"top\"></a>\n",
    "# <div style=\"box-shadow: rgb(60, 121, 245) 0px 0px 0px 3px inset, rgb(255, 255, 255) 10px -10px 0px -3px, rgb(31, 193, 27) 10px -10px, rgb(255, 255, 255) 20px -20px 0px -3px, rgb(255, 217, 19) 20px -20px, rgb(255, 255, 255) 30px -30px 0px -3px, rgb(255, 156, 85) 30px -30px, rgb(255, 255, 255) 40px -40px 0px -3px, rgb(255, 85, 85) 40px -40px; padding:20px; margin-right: 40px; font-size:30px; font-family: consolas; text-align:center; display:fill; border-radius:15px; color:rgb(60, 121, 245);\"><b>Table of contents</b></div>\n",
    "\n",
    "<div style=\"background-color: rgba(60, 121, 245, 0.03); padding:30px; font-size:15px; font-family: consolas;\">\n",
    "<ul>\n",
    "    <li><a href=\"#1\" target=\"_self\" rel=\" noreferrer nofollow\">1. Setting Up Working Environment & Getting Started </a> </li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">2. Checking Harmful Output </a></li>\n",
    "    <li><a href=\"#3\" target=\"_self\" rel=\" noreferrer nofollow\">3. Checking Instruction Following </a></li> \n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa23b71",
   "metadata": {
    "papermill": {
     "duration": 0.006188,
     "end_time": "2024-04-20T18:36:50.169643",
     "exception": false,
     "start_time": "2024-04-20T18:36:50.163455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 1. Setting Up Working Environment & GettingÂ Started </b></div>\n",
    "\n",
    "\n",
    "\n",
    "We will use the OpenAI Python library to access the OpenAI API. You can this Python library using pip like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e51a0ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:31.638061Z",
     "iopub.status.busy": "2025-12-31T12:17:31.637795Z",
     "iopub.status.idle": "2025-12-31T12:17:33.365067Z",
     "shell.execute_reply": "2025-12-31T12:17:33.364430Z"
    },
    "papermill": {
     "duration": 15.929915,
     "end_time": "2024-04-20T18:37:06.106278",
     "exception": false,
     "start_time": "2024-04-20T18:36:50.176363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\administrator\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eca19b",
   "metadata": {
    "papermill": {
     "duration": 0.007841,
     "end_time": "2024-04-20T18:37:06.122236",
     "exception": false,
     "start_time": "2024-04-20T18:37:06.114395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we will import **OpenAI** and then set the OpenAI API key which is a secret key. You can get one of these API keys from the OpenAI website. It is better to set this as an environment variable to keep it safe if you share your code. We will use OpenAI's chatGPT GPT 3.5 Turbo model, and the chat completions endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a610d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:33.367827Z",
     "iopub.status.busy": "2025-12-31T12:17:33.367637Z",
     "iopub.status.idle": "2025-12-31T12:17:39.291092Z",
     "shell.execute_reply": "2025-12-31T12:17:39.290634Z"
    },
    "papermill": {
     "duration": 1.032947,
     "end_time": "2024-04-20T18:37:07.163574",
     "exception": false,
     "start_time": "2024-04-20T18:37:06.130627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16672\\312141790.py:41: UserWarning: Using Panel interactively in VSCode notebooks requires the jupyter_bokeh package to be installed. You can install it with:\n",
      "\n",
      "   pip install jupyter_bokeh\n",
      "\n",
      "or:\n",
      "    conda install jupyter_bokeh\n",
      "\n",
      "and try again.\n",
      "  pn.extension()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.7.0/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.7.0/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='c8bf2e75-9441-4bae-8832-6fe2ff2d3c3b'>\n",
       "  <div id=\"b2bbd888-57c8-4da8-8497-8bc9997bd145\" data-root-id=\"c8bf2e75-9441-4bae-8832-6fe2ff2d3c3b\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"e48ba7c9-c3c7-4945-8143-5107c59f2a85\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"c8bf2e75-9441-4bae-8832-6fe2ff2d3c3b\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"402be56f-5fa0-4478-81c2-683669a16110\",\"attributes\":{\"plot_id\":\"c8bf2e75-9441-4bae-8832-6fe2ff2d3c3b\",\"comm_id\":\"624da243e07a46338818e833d87ded2d\",\"client_comm_id\":\"9f36937be8d0478b95e2edaff2c26d84\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"e48ba7c9-c3c7-4945-8143-5107c59f2a85\",\"roots\":{\"c8bf2e75-9441-4bae-8832-6fe2ff2d3c3b\":\"b2bbd888-57c8-4da8-8497-8bc9997bd145\"},\"root_ids\":[\"c8bf2e75-9441-4bae-8832-6fe2ff2d3c3b\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "c8bf2e75-9441-4bae-8832-6fe2ff2d3c3b"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "import panel as pn\n",
    "from openai import OpenAI\n",
    "from dotenv import dotenv_values\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ==============================\n",
    "# ðŸ”‘ Load environment variables\n",
    "# ==============================\n",
    "env_values = dotenv_values(\".env\")\n",
    "\n",
    "openai_api_key = env_values.get(\"OPENAI_API_KEY\")\n",
    "openai_api_base = env_values.get(\"OPENAI_API_BASE\")\n",
    "openai_api_name = env_values.get(\"OPENAI_API_NAME\")\n",
    "\n",
    "# Initialize Clients\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base\n",
    ")\n",
    "\n",
    "# Mock moderation for OpenRouter compatibility\n",
    "if openai_api_base and \"openrouter.ai\" in openai_api_base:\n",
    "    class MockResult(dict):\n",
    "        def __getattr__(self, name): return self.get(name)\n",
    "    class MockModeration(dict):\n",
    "        def __init__(self):\n",
    "            res = MockResult(flagged=False, categories={}, category_scores={})\n",
    "            super().__init__(results=[res])\n",
    "        @property\n",
    "        def results(self): return self[\"results\"]\n",
    "    client.moderations.create = lambda *args, **kwargs: MockModeration()\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=openai_api_name, \n",
    "    openai_api_key=openai_api_key, \n",
    "    openai_api_base=openai_api_base,\n",
    "    temperature=0.7\n",
    ")\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1909a4",
   "metadata": {
    "papermill": {
     "duration": 0.007974,
     "end_time": "2024-04-20T18:37:07.179976",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.172002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we will define a helper function to make it easier to use prompts and look at generated outputs. So that's this function, get_completion, that just takes in a prompt and will return the completion for that prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc33d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:39.293042Z",
     "iopub.status.busy": "2025-12-31T12:17:39.292775Z",
     "iopub.status.idle": "2025-12-31T12:17:39.295958Z",
     "shell.execute_reply": "2025-12-31T12:17:39.295242Z"
    },
    "papermill": {
     "duration": 0.017578,
     "end_time": "2024-04-20T18:37:07.205879",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.188301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# ðŸ”§ Helper Functions\n",
    "# ==============================\n",
    "def get_completion(prompt, model=openai_api_name, temperature=0, max_tokens=500):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_completion_from_messages(messages, model=openai_api_name, temperature=0, max_tokens=500):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8dac9d",
   "metadata": {
    "papermill": {
     "duration": 0.008193,
     "end_time": "2024-04-20T18:37:07.222315",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.214122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 2. Checking HarmfulÂ Output </b></div>\n",
    "\n",
    "\n",
    "Moderation API can be used to filter and moderate outputs generated by the system itself. In the example below we will pass a generated response to the user and we're going to use the moderation API to see if this output is flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df8b3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:39.298549Z",
     "iopub.status.busy": "2025-12-31T12:17:39.298312Z",
     "iopub.status.idle": "2025-12-31T12:17:39.302146Z",
     "shell.execute_reply": "2025-12-31T12:17:39.301754Z"
    },
    "papermill": {
     "duration": 0.35016,
     "end_time": "2024-04-20T18:37:07.580567",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.230407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flagged': False, 'categories': {}, 'category_scores': {}}\n"
     ]
    }
   ],
   "source": [
    "final_response_to_customer = f\"\"\"\n",
    "Introducing our latest tech lineup! The MegaScreen \\\n",
    "Tablet boasts a massive 10.5-inch display, 256GB storage, \\\n",
    "dual rear cameras, and lightning-fast 5G connectivity. \\\n",
    "Looking to capture breathtaking moments? \\\n",
    "Our ProCapture DSLR Camera sports a 30.4MP sensor, \\\n",
    "4K video recording, articulating touchscreen, \\\n",
    "and a range of compatible lenses. Dive into immersive entertainment \\\n",
    "with our VisionX 8K TV, featuring an expansive 75-inch display, \\\n",
    "cutting-edge 8K resolution, Dolby Vision HDR, and intuitive smart \\ \n",
    "TV capabilities. Enhance your audio experience with our SonicWave \\\n",
    "Surround Sound System, delivering 7.1 channel audio, 1500W output, \\\n",
    "wireless rear speakers, and seamless Bluetooth connectivity. \\\n",
    "Have inquiries about these top-notch products or any others \\\n",
    "in our catalog? Feel free to ask!\n",
    "\"\"\"\n",
    "response = client.moderations.create(\n",
    "    input=final_response_to_customer\n",
    ")\n",
    "moderation_output = response.results[0]\n",
    "\n",
    "print(moderation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea40cd2e",
   "metadata": {
    "papermill": {
     "duration": 0.007969,
     "end_time": "2024-04-20T18:37:07.597956",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.589987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, this output is not flagged and has shallow scores in all categories, which makes sense given the response. Let's take another response that has some harassment and is not safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb64c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:39.303959Z",
     "iopub.status.busy": "2025-12-31T12:17:39.303713Z",
     "iopub.status.idle": "2025-12-31T12:17:39.306840Z",
     "shell.execute_reply": "2025-12-31T12:17:39.306457Z"
    },
    "papermill": {
     "duration": 0.381279,
     "end_time": "2024-04-20T18:37:07.987461",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.606182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flagged': False, 'categories': {}, 'category_scores': {}}\n"
     ]
    }
   ],
   "source": [
    "final_response_to_customer = f\"\"\"\n",
    "Introducing our latest tech lineup! The MegaScreen \\\n",
    "Tablet boasts a massive 10.5-inch display, 256GB storage, \\\n",
    "dual rear cameras, and lightning-fast 5G connectivity. \\\n",
    "Looking to capture breathtaking moments and feel the real horror? \\\n",
    "Our ProCapture DSLR Camera sports a 30.4MP sensor, \\\n",
    "4K video recording, articulating touchscreen, \\\n",
    "and a range of compatible lenses. Dive into immersive entertainment \\ with our VisionX 8K TV, featuring an expansive 75-inch display, \\\n",
    "cutting-edge 8K resolution, Dolby Vision HDR, and intuitive smart \\ \n",
    "TV capabilities. Enhance your shitty audio experience with our SonicWave \\\n",
    "Surround Sound System, delivering 7.1 channel audio, 1500W output, \\\n",
    "wireless rear speakers, and seamless Bluetooth connectivity. \\\n",
    "Have inquiries about these top-notch products or any others \\\n",
    "in our catalog? Feel free to ask althoug I know you are stupid and did not \n",
    "understand anything!\n",
    "\"\"\"\n",
    "\n",
    "response = client.moderations.create(\n",
    "    input=final_response_to_customer\n",
    ")\n",
    "moderation_output = response.results[0]\n",
    "\n",
    "print(moderation_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771903bd",
   "metadata": {
    "papermill": {
     "duration": 0.00849,
     "end_time": "2024-04-20T18:37:08.004418",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.995928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see now that the response is flagged and the harassment score is high. In general, it can also be important to check the outputs. For example, if you were creating a chatbot for sensitive audiences, you could use lower thresholds for flagging outputs.Â \n",
    "\n",
    "In general, if the moderation output indicates that the content is flagged, you can take appropriate action such as responding with a fallback answer or generating a new response. Note that as we improve the models, they also are becoming less and less likely to return some kind of harmful output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82051c7",
   "metadata": {
    "papermill": {
     "duration": 0.008388,
     "end_time": "2024-04-20T18:37:08.021015",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.012627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 3. Checking Instruction Following </b></div>\n",
    "\n",
    "\n",
    "Another approach for checking outputs is asking the model itself if the generated was satisfactory and if it follows a rubric you define. This can be done by providing the generated output as part of the input to the model and asking it to rate the quality of the output. \n",
    "\n",
    "You can do this in various ways.Â \n",
    "So let's see an example in which our system message is \"**You are an assistant that evaluates whether customer service agent responses sufficiently answer customer questions and also validates that all the facts the assistant cites from the product information are correct. The product information and user and customer service agent messages will be delivered by three backticks. respond with a Y or N character with no punctuation. Y if the output sufficiently answers the question and the response correctly uses product information and no otherwise. Output a single letter only**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fc1472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:39.308431Z",
     "iopub.status.busy": "2025-12-31T12:17:39.308255Z",
     "iopub.status.idle": "2025-12-31T12:17:39.311036Z",
     "shell.execute_reply": "2025-12-31T12:17:39.310628Z"
    },
    "papermill": {
     "duration": 0.017477,
     "end_time": "2024-04-20T18:37:08.046793",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.029316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are an assistant that evaluates whether \\\n",
    "customer service agent responses sufficiently \\\n",
    "answer customer questions, and also validates that \\\n",
    "all the facts the assistant cites from the product \\\n",
    "information are correct.\n",
    "The product information and user and customer \\\n",
    "service agent messages will be delimited by \\\n",
    "3 backticks, i.e. ```.\n",
    "Respond with a Y or N character, with no punctuation:\n",
    "Y - if the output sufficiently answers the question \\\n",
    "AND the response correctly uses product information\n",
    "N - otherwise\n",
    "\n",
    "Output a single letter only.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06834ba5",
   "metadata": {
    "papermill": {
     "duration": 0.008498,
     "end_time": "2024-04-20T18:37:08.063514",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.055016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You could also add some other kinds of guidelines. You could ask, or give a rubric, like a rubric for an exam or essay grading. You could use that format and say, does this use a friendly tone and maybe outline some of your brand guidelines.\n",
    "\n",
    "So let's add our customer message and the product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f7306a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:39.313463Z",
     "iopub.status.busy": "2025-12-31T12:17:39.313244Z",
     "iopub.status.idle": "2025-12-31T12:17:39.317070Z",
     "shell.execute_reply": "2025-12-31T12:17:39.316573Z"
    },
    "papermill": {
     "duration": 0.018931,
     "end_time": "2024-04-20T18:37:08.090746",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.071815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_message = f\"\"\"\n",
    "tell me about the smartx pro phone and \\\n",
    "the fotosnap camera, the dslr one. \\\n",
    "Also tell me about your tvs\"\"\"\n",
    "\n",
    "product_information = \"\"\"{ \"name\": \"SmartX ProPhone\", \"category\": \"Smartphones and Accessories\", \"brand\": \"SmartX\", \"model_number\": \"SX-PP10\", \"warranty\": \"1 year\", \"rating\": 4.6, \"features\": [ \"6.1-inch display\", \"128GB storage\", \"12MP dual camera\", \"5G\" ], \"description\": \"A powerful smartphone with advanced camera features.\", \"price\": 899.99 } { \"name\": \"FotoSnap DSLR Camera\", \"category\": \"Cameras and Camcorders\", \"brand\": \"FotoSnap\", \"model_number\": \"FS-DSLR200\", \"warranty\": \"1 year\", \"rating\": 4.7, \"features\": [ \"24.2MP sensor\", \"1080p video\", \"3-inch LCD\", \"Interchangeable lenses\" ], \"description\": \"Capture stunning photos and videos with this versatile DSLR camera.\", \"price\": 599.99 } { \"name\": \"CineView 4K TV\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"CineView\", \"model_number\": \"CV-4K55\", \"warranty\": \"2 years\", \"rating\": 4.8, \"features\": [ \"55-inch display\", \"4K resolution\", \"HDR\", \"Smart TV\" ], \"description\": \"A stunning 4K TV with vibrant colors and smart features.\", \"price\": 599.99 } { \"name\": \"SoundMax Home Theater\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"SoundMax\", \"model_number\": \"SM-HT100\", \"warranty\": \"1 year\", \"rating\": 4.4, \"features\": [ \"5.1 channel\", \"1000W output\", \"Wireless subwoofer\", \"Bluetooth\" ], \"description\": \"A powerful home theater system for an immersive audio experience.\", \"price\": 399.99 } { \"name\": \"CineView 8K TV\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"CineView\", \"model_number\": \"CV-8K65\", \"warranty\": \"2 years\", \"rating\": 4.9, \"features\": [ \"65-inch display\", \"8K resolution\", \"HDR\", \"Smart TV\" ], \"description\": \"Experience the future of television with this stunning 8K TV.\", \"price\": 2999.99 } { \"name\": \"SoundMax Soundbar\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"SoundMax\", \"model_number\": \"SM-SB50\", \"warranty\": \"1 year\", \"rating\": 4.3, \"features\": [ \"2.1 channel\", \"300W output\", \"Wireless subwoofer\", \"Bluetooth\" ], \"description\": \"Upgrade your TV's audio with this sleek and powerful soundbar.\", \"price\": 199.99 } { \"name\": \"CineView OLED TV\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"CineView\", \"model_number\": \"CV-OLED55\", \"warranty\": \"2 years\", \"rating\": 4.7, \"features\": [ \"55-inch display\", \"4K resolution\", \"HDR\", \"Smart TV\" ], \"description\": \"Experience true blacks and vibrant colors with this OLED TV.\", \"price\": 1499.99 }\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22413e72",
   "metadata": {
    "papermill": {
     "duration": 0.00859,
     "end_time": "2024-04-20T18:37:08.108014",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.099424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Now we will define the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d133ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:39.318750Z",
     "iopub.status.busy": "2025-12-31T12:17:39.318543Z",
     "iopub.status.idle": "2025-12-31T12:17:39.321087Z",
     "shell.execute_reply": "2025-12-31T12:17:39.320742Z"
    },
    "papermill": {
     "duration": 0.01789,
     "end_time": "2024-04-20T18:37:08.134586",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.116696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_a_pair = f\"\"\"\n",
    "Customer message: ```{customer_message}```\n",
    "Product information: ```{product_information}```\n",
    "Agent response: ```{final_response_to_customer}```\n",
    "\n",
    "Does the response use the retrieved information correctly?\n",
    "Does the response sufficiently answer the question\n",
    "\n",
    "Output Y or N\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ec427",
   "metadata": {
    "papermill": {
     "duration": 0.008476,
     "end_time": "2024-04-20T18:37:08.151545",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.143069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Finally, we will format this into a messages list and get the response from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ef889ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:39.322848Z",
     "iopub.status.busy": "2025-12-31T12:17:39.322659Z",
     "iopub.status.idle": "2025-12-31T12:17:40.080766Z",
     "shell.execute_reply": "2025-12-31T12:17:40.080004Z"
    },
    "papermill": {
     "duration": 0.578375,
     "end_time": "2024-04-20T18:37:08.738112",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.159737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': q_a_pair}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, max_tokens=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48bae9",
   "metadata": {
    "papermill": {
     "duration": 0.008827,
     "end_time": "2024-04-20T18:37:08.756329",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.747502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So the model says yes, the product information is correct and the question is answered sufficiently.Â \n",
    "Let's try another response which is \"**Life is like a box of chocolates**.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7031657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:40.084359Z",
     "iopub.status.busy": "2025-12-31T12:17:40.083980Z",
     "iopub.status.idle": "2025-12-31T12:17:40.088386Z",
     "shell.execute_reply": "2025-12-31T12:17:40.087585Z"
    },
    "papermill": {
     "duration": 0.016665,
     "end_time": "2024-04-20T18:37:08.781854",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.765189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "another_response = \"life is like a box of chocolates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3e49c",
   "metadata": {
    "papermill": {
     "duration": 0.008736,
     "end_time": "2024-04-20T18:37:08.799606",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.790870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So let's add our message to do with the output checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cddbae9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:17:40.093027Z",
     "iopub.status.busy": "2025-12-31T12:17:40.092687Z",
     "iopub.status.idle": "2025-12-31T12:17:40.578275Z",
     "shell.execute_reply": "2025-12-31T12:17:40.577187Z"
    },
    "papermill": {
     "duration": 0.552485,
     "end_time": "2024-04-20T18:37:09.360884",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.808399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "q_a_pair = f\"\"\"\n",
    "Customer message: ```{customer_message}```\n",
    "Product information: ```{product_information}```\n",
    "Agent response: ```{another_response}```\n",
    "\n",
    "Does the response use the retrieved information correctly?\n",
    "Does the response sufficiently answer the question?\n",
    "\n",
    "Output Y or N\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': q_a_pair}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f2ab4",
   "metadata": {
    "papermill": {
     "duration": 0.009103,
     "end_time": "2024-04-20T18:37:09.379326",
     "exception": false,
     "start_time": "2024-04-20T18:37:09.370223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model has determined that this does not sufficiently answer the question or use the retrieved information.\n",
    "The question we used here \"Does the response use the retrieved information correctly? Does the response sufficiently answer the question?\" is a good prompt to use if you want to make sure that the model isn't hallucinating and is not making up things that aren't true.Â \n",
    "\n",
    "As you can see, the model can provide feedback on the quality of a generated output, and you can use this feedback to decide whether to present the output to the user or to generate a new response.Â \n",
    "\n",
    "You could even experiment with generating multiple model responses per user query, and then having the model choose the best one to show the user.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7238719",
   "metadata": {
    "papermill": {
     "duration": 0.008982,
     "end_time": "2024-04-20T18:37:09.397849",
     "exception": false,
     "start_time": "2024-04-20T18:37:09.388867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " In general, it is advisable to use the moderation API to validate outputs, as it promotes responsible and ethical usage. While there is a possibility of obtaining immediate feedback by asking the model to evaluate itself in certain cases, it appears to be largely unnecessary, particularly with advanced models such as GPT-4.\n",
    " \n",
    "From my experience, this method is not frequently utilized in practice. Additionally, implementing it would result in increased system delay and expenses, as it requires an extra model call and additional tokens.\n",
    "\n",
    "If achieving an extremely low error rate of 0.00001% is crucial for your Apple product, then this approach may be worth considering. However, overall, I would not recommend adopting it as a standard practice in general circumstances."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.660294,
   "end_time": "2024-04-20T18:37:09.945647",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-20T18:36:47.285353",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
