{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 9073223,
     "sourceType": "datasetVersion",
     "datasetId": 5473065
    }
   ],
   "dockerImageVersionId": 31154,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "colab": {
   "name": "Evaluating LLM Applications Using LangChain",
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/mohamedehab0122/evaluating-llm-applications-using-langchain.3df7f6a7-9837-4749-b253-235b3f7c083a.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20251027/auto/storage/goog4_request&X-Goog-Date=20251027T141424Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=67a9dc478fe43947306082f61daa998e7630dd6a3240b451cf6cbb14d4316e47484bb5956d3a2808a5318c1c78a8c52ae8262a06d19616f5503159ac8231a178d733ae657e2fd12803cc089965133bd60b2c5ae56b507c4b7ae3a7670224a937e241105e635dbd688338cc7a67aca5997961ac3a21ce6d80430e29d7c50e258e834b22dcda603ebc8fde3de5eafe30c440e0494055a9c244d83c56a4598861c3c7d0e1a0d3af652a0b203e20ae186f29ac21e5925b95891f52de4ef37b2d7ed301789b4fc4f3f8db2cee02b5f17c0d764c748750cd0f98c0696f3655f413d858d2f273ce48f33477e6505c33efcd71827b0f33ee074ab7ceeb583229474a7ddf",
     "timestamp": 1761574482996
    }
   ]
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "# import kagglehub\n",
    "# ivanj0_ebook_how_to_build_a_career_in_ai_path = kagglehub.dataset_download('ivanj0/ebook-how-to-build-a-career-in-ai')\n",
    "ivanj0_ebook_how_to_build_a_career_in_ai_path = \"./data/ivanj0/ebook-how-to-build-a-career-in-ai\"\n",
    "\n",
    "print('Data source import complete.')\n"
   ],
   "metadata": {
    "id": "CrD7EL3WBUfp"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Manual Evaluation & Debugging  \n",
    "### Understanding Evaluation in LangChain\n",
    "\n",
    "---\n",
    "\n",
    "##  Manual Evaluation\n",
    "\n",
    "**Manual evaluation** means *you, the developer, test and analyze the model\u2019s outputs manually* \u2014 rather than relying on automated metrics.  \n",
    "This approach is useful when:\n",
    "\n",
    "- The task involves **subjective quality** (e.g., reasoning, creativity, or helpfulness).  \n",
    "- You need to **understand model behavior** and identify failure patterns.  \n",
    "- You are still **iterating on prompts, chains, or agents** and want to see internal logic.\n",
    "\n",
    "### \ud83d\udd0dTypical Manual Evaluation Steps\n",
    "\n",
    "1. **Run sample inputs** through your chain or LLM.  \n",
    "2. **Inspect the outputs** for accuracy, consistency, and reasoning quality.  \n",
    "3. **Compare** them with expected outputs (if available).  \n",
    "4. **Document issues or failure patterns**.  \n",
    "5. **Refine prompts or chain structure** based on the observations.\n",
    "\n",
    "\ud83e\udde9 Manual evaluation helps you deeply understand *why* your chain behaves a certain way \u2014 which is critical before scaling automated evaluations.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83e\udd16 LLM-Assisted Evaluation (LangChain)\n",
    "\n",
    "LangChain provides **LLM-assisted evaluation**, where a **larger or more capable model** acts as a *judge* to assess how well your chain or model performs.\n",
    "\n",
    "Instead of manually grading responses, another LLM evaluates them based on specific **criteria or evaluation prompts**.\n",
    "\n",
    "### \ud83e\udde0 How It Works\n",
    "\n",
    "1. You define or load an **evaluation chain** (e.g., \u201cQA evaluator\u201d).  \n",
    "2. The evaluator LLM receives:\n",
    "   - The **input** to your system  \n",
    "   - The **predicted output**  \n",
    "   - Optionally, the **reference or ground truth output**  \n",
    "3. The LLM then produces a **score or qualitative feedback**  \n",
    "   (e.g., correctness, coherence, or helpfulness).  \n",
    "4. You can use these scores to **compare models, prompts, or chain versions**.\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "KSOog8pdBUfq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain langchain-openai langchain langchain-openai_community openai docarray  sentence-transformers transformers huggingface-hub langchain-community python-dotenv\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "id": "UOSuZ36DBUfr"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence,RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "model=\"gpt-3.5-turbo\"\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:49:54.648855Z",
     "iopub.execute_input": "2025-10-27T13:49:54.649128Z",
     "iopub.status.idle": "2025-10-27T13:50:05.24536Z",
     "shell.execute_reply.started": "2025-10-27T13:49:54.649106Z",
     "shell.execute_reply": "2025-10-27T13:50:05.244725Z"
    },
    "id": "_IGanvjgBUfr"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import PyPDFLoader\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:05.24606Z",
     "iopub.execute_input": "2025-10-27T13:50:05.246435Z",
     "iopub.status.idle": "2025-10-27T13:50:06.264513Z",
     "shell.execute_reply.started": "2025-10-27T13:50:05.246415Z",
     "shell.execute_reply": "2025-10-27T13:50:06.26372Z"
    },
    "id": "DesgZhWyBUfr"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=1,\n",
    "    api_key=openai_api_key,\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:06.266498Z",
     "iopub.execute_input": "2025-10-27T13:50:06.266712Z",
     "iopub.status.idle": "2025-10-27T13:50:06.809899Z",
     "shell.execute_reply.started": "2025-10-27T13:50:06.266695Z",
     "shell.execute_reply": "2025-10-27T13:50:06.809368Z"
    },
    "id": "1VdXmzNmBUfr",
    "outputId": "665df007-9efd-482b-be77-d00763ee56a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_37/677866108.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n  llm = ChatOpenAI(\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "file = f'{ivanj0_ebook_how_to_build_a_career_in_ai_path}/eBook-How-to-Build-a-Career-in-AI.pdf'\n",
    "loader = PyPDFLoader(file_path=file)\n",
    "data = loader.load()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:06.810605Z",
     "iopub.execute_input": "2025-10-27T13:50:06.81085Z",
     "iopub.status.idle": "2025-10-27T13:50:08.129816Z",
     "shell.execute_reply.started": "2025-10-27T13:50:06.810826Z",
     "shell.execute_reply": "2025-10-27T13:50:08.129244Z"
    },
    "id": "86kI8V0aBUfs"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true,
    "id": "YTxxKCr6BUfs"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "embedding = SentenceTransformerEmbeddings(model_name=model_name)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:08.130602Z",
     "iopub.execute_input": "2025-10-27T13:50:08.131032Z",
     "iopub.status.idle": "2025-10-27T13:50:37.059531Z",
     "shell.execute_reply.started": "2025-10-27T13:50:08.131007Z",
     "shell.execute_reply": "2025-10-27T13:50:37.058681Z"
    },
    "id": "znYlSWrlBUfs",
    "outputId": "4f3e41ae-fe60-4c1a-9eff-4a4d9ea0f97c",
    "colab": {
     "referenced_widgets": [
      "5cdcaa0d8cbb41d49aa91cfcf8689c92",
      "8c645e67252b46e29c05a7289de82d11",
      "939b2f46c66845e6b2ed6d65909a1950",
      "60cecca74ae3473a842bc118449bcd96",
      "dfc82e6ddd7447879a8151063e0c2be8",
      "d6699c79602e411cb79b795b197a727b",
      "492c97f8f8224ef68e6057752076a9cf",
      "9d5b9eb0c5844641853735eb0ff22d2e",
      "30eabf216e4945309825989cb8949d37",
      "5caa579dca364c4498edd3a5284f55d6",
      "7a0ece6853a044688d10b351c7794460"
     ]
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_37/3820025957.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embedding = SentenceTransformerEmbeddings(model_name=model_name)\n2025-10-27 13:50:15.298529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761573015.471049      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761573015.525966      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cdcaa0d8cbb41d49aa91cfcf8689c92"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c645e67252b46e29c05a7289de82d11"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "README.md: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "939b2f46c66845e6b2ed6d65909a1950"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60cecca74ae3473a842bc118449bcd96"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfc82e6ddd7447879a8151063e0c2be8"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6699c79602e411cb79b795b197a727b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "492c97f8f8224ef68e6057752076a9cf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d5b9eb0c5844641853735eb0ff22d2e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30eabf216e4945309825989cb8949d37"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5caa579dca364c4498edd3a5284f55d6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a0ece6853a044688d10b351c7794460"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Try BAAI/bge-small-en-v1.5 instead\n",
    "\n",
    "\n",
    "\n",
    "# Create the vector store index\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embedding  # Include the Transformers embedding model\n",
    ").from_loaders([loader])\n",
    "\n",
    "# Initialize the language model\n",
    "\n",
    "# Create the QA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:37.060377Z",
     "iopub.execute_input": "2025-10-27T13:50:37.060603Z",
     "iopub.status.idle": "2025-10-27T13:50:38.297998Z",
     "shell.execute_reply.started": "2025-10-27T13:50:37.060576Z",
     "shell.execute_reply": "2025-10-27T13:50:38.297419Z"
    },
    "id": "1-r9eCurBUfs",
    "outputId": "09c435c5-9de3-4f91-dd37-cdc7062f973b"
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\nINFO - docarray - DB config created\nINFO - docarray - Runtime config created\nINFO - docarray - No docs or index file provided. Initializing empty InMemoryExactNNIndex.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data[10]\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:38.298792Z",
     "iopub.execute_input": "2025-10-27T13:50:38.299076Z",
     "iopub.status.idle": "2025-10-27T13:50:38.304702Z",
     "shell.execute_reply.started": "2025-10-27T13:50:38.299047Z",
     "shell.execute_reply": "2025-10-27T13:50:38.303854Z"
    },
    "id": "RMmi16vtBUft",
    "outputId": "2a888f29-33e6-47e0-b65f-d17b0c043e49"
   },
   "outputs": [
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': '/kaggle/input/ebook-how-to-build-a-career-in-ai/eBook-How-to-Build-a-Career-in-AI.pdf', 'total_pages': 41, 'page': 10, 'page_label': '11'}, page_content='PAGE 11\\nThe Best Way to Build \\na New Habit\\nOne of my favorite books is BJ Fogg\u2019s, Tiny Habits: The Small Changes That Change \\nEverything. Fogg explains that the best way to build a new habit is to start small \\nand succeed, rather than start  too big and fail. For example, rather than trying to \\nexercise for 30 minutes a day, he recommends aspiring to do just one push-up, and \\ndoing it consistently.\\nThis approach may be helpful to those of you who want to spend more time studying. \\nIf you start by holding yourself accountable for watching, say, 10 seconds of an \\neducational video every day \u2014 and you do so consistently \u2014 the habit of studying daily \\nwill grow naturally. Even if you learn nothing in that 10 seconds, you\u2019re establishing the \\nhabit of studying a little every day. On some days, maybe you\u2019ll end up studying for an \\nhour or longer.')"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data[8]"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:38.305555Z",
     "iopub.execute_input": "2025-10-27T13:50:38.305886Z",
     "iopub.status.idle": "2025-10-27T13:50:38.32165Z",
     "shell.execute_reply.started": "2025-10-27T13:50:38.305862Z",
     "shell.execute_reply": "2025-10-27T13:50:38.321022Z"
    },
    "id": "t2Cttlh7BUft",
    "outputId": "69387481-f4df-4aa1-dea7-7a3b78283a45"
   },
   "outputs": [
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': '/kaggle/input/ebook-how-to-build-a-career-in-ai/eBook-How-to-Build-a-Career-in-AI.pdf', 'total_pages': 41, 'page': 8, 'page_label': '9'}, page_content='PAGE 9\\nIn the previous chapter, I introduced three key steps for building a career in AI: learning \\nfoundational technical skills, working on projects, and finding a job, all of which is supported \\nby being part of a community. In this chapter, I\u2019d like to dive more deeply into the first step: \\nlearning foundational skills.\\nMore research papers have been published on AI than anyone can read in a lifetime. So, when \\nlearning, it\u2019s critical to prioritize topic selection. I believe the most important topics for a technical \\ncareer in machine learning are:\\nFoundational machine learning skills: For example, it\u2019s important to understand models such \\nas linear regression, logistic regression, neural networks, decision trees, clustering, and anomaly \\ndetection. Beyond specific models, it\u2019s even more important to understand the core concepts \\nbehind how and why machine learning works, such as bias/variance, cost functions, regularization, \\noptimization algorithms, and error analysis.\\nDeep learning: This has become such a large fraction of machine learning that it\u2019s hard to excel \\nin the field without some understanding of it! It\u2019s valuable to know the basics of neural networks, \\npractical skills for making them work (such as hyperparameter tuning), convolutional networks, \\nsequence models, and transformers.\\nSoftware development: While you can get a job and make huge contributions with only machine \\nlearning modeling skills, your job opportunities will increase if you can also write good software \\nto implement complex AI systems. These skills include programming fundamentals, data \\nstructures (especially those that relate to machine learning, such as data frames), algorithms \\n(including those related to databases and data manipulation), software design, familiarity with \\nPython, and familiarity with key libraries such as TensorFlow or PyTorch, and scikit-learn.\\nMath relevant to machine learning: Key areas include linear algebra (vectors, matrices, and various \\nmanipulations of them) as well as probability and statistics (including discrete and continuous \\nprobability, standard probability distributions, basic rules such as independence and Bayes\u2019 rule, \\nand hypothesis testing). In addition, exploratory data analysis (EDA) \u2014 using visualizations and other \\nmethods to systematically explore a dataset \u2014 is an underrated skill. I\u2019ve found EDA particularly \\nuseful in data-centric AI development, where analyzing errors and gaining insights can really help \\ndrive progress! Finally, a basic intuitive understanding of calculus will also help. The math needed \\nto do machine learning well has been changing. For instance, although some tasks require calculus, \\nimproved automatic differentiation software makes it possible to invent and implement new neural \\nnetwork architectures without doing any calculus. This was almost impossible a decade ago.\\nLearning Technical Skills For a Promising AI Career CHAPTER 2')"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What is the best way to build a new habit?\",\n",
    "        \"answer\": \"Start small and be consistent\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Who wrote the book Tiny Habits?\",\n",
    "        \"answer\": \"BJ Fogg\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are the key Python frameworks to learn for AI?\",\n",
    "        \"answer\": \"TensorFlow and PyTorch\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Is understanding machine learning foundations important?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:38.323388Z",
     "iopub.execute_input": "2025-10-27T13:50:38.323819Z",
     "iopub.status.idle": "2025-10-27T13:50:38.336264Z",
     "shell.execute_reply.started": "2025-10-27T13:50:38.323802Z",
     "shell.execute_reply": "2025-10-27T13:50:38.335493Z"
    },
    "id": "NdbiRH0zBUft"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# model is good but is native way for long answer\n",
    "\n",
    "print(\" Starting Manual Evaluation...\\n\")\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i, ex in enumerate(examples, start=1):\n",
    "    print(f\" Query {i}: {ex['query']}\")\n",
    "\n",
    "    response = qa.run(ex[\"query\"])\n",
    "\n",
    "    print(f\" Model Answer: {response}\")\n",
    "    print(f\" Expected Answer: {ex['answer']}\")\n",
    "\n",
    "    if ex[\"answer\"].lower() in response.lower():\n",
    "        print(\" Correct!\\n\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(\" Incorrect.\\n\")\n",
    "\n",
    "accuracy = correct / len(examples)\n",
    "print(f\" Final Manual Evaluation Accuracy: {accuracy*100:.1f}%\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:50:38.336955Z",
     "iopub.execute_input": "2025-10-27T13:50:38.337287Z",
     "iopub.status.idle": "2025-10-27T13:50:40.603576Z",
     "shell.execute_reply.started": "2025-10-27T13:50:38.337265Z",
     "shell.execute_reply": "2025-10-27T13:50:40.602711Z"
    },
    "id": "3SBhemuABUft",
    "outputId": "d66b282d-8b3b-4361-bbd5-15543532a123"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": " Starting Manual Evaluation...\n\n Query 1: What is the best way to build a new habit?\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_37/2097026613.py:10: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  response = qa.run(ex[\"query\"])\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\n\u001b[1m> Finished chain.\u001b[0m\n Model Answer: The best way to build a new habit is to **start tiny and focus on consistent success**.  \n- **Pick a micro\u2011task** that takes only a few seconds or minutes\u2014e.g., one push\u2011up, or watching just 10\u202fseconds of an educational video.  \n- **Do it every day** until the action becomes automatic.  \n- **Let the habit grow**: as you get comfortable, the time or effort can naturally expand, but the key is that the initial tiny step is almost always achievable, which builds confidence and momentum.\n\nThis \u201cstart small, succeed, and let the habit build\u201d approach\u2014popularized by BJ\u202fFogg in *Tiny Habits*\u2014is more reliable than launching into a big, ambitious goal that often leads to failure.\n Expected Answer: Start small and be consistent\n Incorrect.\n\n Query 2: Who wrote the book Tiny Habits?\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n Model Answer: The book *Tiny Habits: The Small Changes That Change Everything* was written by BJ\u202fFogg.\n Expected Answer: BJ Fogg\n Incorrect.\n\n Query 3: What are the key Python frameworks to learn for AI?\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n Model Answer: **Key Python frameworks and libraries you should master for an AI career**\n\n| Category | Framework / Library | Why it matters |\n|----------|---------------------|----------------|\n| **Deep learning** | **TensorFlow** (and its high\u2011level API Keras) | Google\u2011backed, production\u2011ready, wide adoption. |\n| | **PyTorch** | Facebook\u2011backed, research\u2011friendly, dynamic graphing. |\n| | **JAX** | NumPy\u2011like API with automatic differentiation; great for research and high\u2011performance computing. |\n| **Large\u2011scale models** | **Hugging Face Transformers** | State\u2011of\u2011the\u2011art NLP & vision models, easy integration with PyTorch/TensorFlow. |\n| **Ensemble / tree\u2011based models** | **XGBoost** | Gradient boosting for tabular data. |\n| | **LightGBM** | Faster, memory\u2011efficient boosting. |\n| | **CatBoost** | Handles categorical features natively. |\n| **General\u2011purpose ML** | **scikit\u2011learn** | Classic algorithms (SVM, RF, KNN) and pipelines for quick prototyping. |\n| **Data manipulation & EDA** | **pandas** | DataFrames, merging, grouping \u2013 the backbone of any data workflow. |\n| | **NumPy / SciPy** | Numerical operations, linear algebra, stats. |\n| | **Matplotlib / Seaborn** | Visualizing data and model results. |\n| **Model deployment** | **FastAPI** / **Flask** | Lightweight web frameworks to expose models as APIs. |\n| | **ONNX** | Interoperable model format for moving models between frameworks. |\n| | **Streamlit / Gradio** | Rapid prototyping of ML demos and dashboards. |\n\n### Quick take\u2011away\n\n- **Deep learning** \u2192 *TensorFlow + PyTorch* (pick one as your core, but know both).\n- **Production** \u2192 *FastAPI/Flask* + *ONNX*.\n- **Data pipeline & EDA** \u2192 *pandas, NumPy, Matplotlib/Seaborn*.\n- **Tabular/ensemble** \u2192 *scikit\u2011learn, XGBoost, LightGBM, CatBoost*.\n- **NLP / vision** \u2192 *Hugging Face Transformers*.\n\nLearning these frameworks gives you the full stack: from data ingestion \u2192 model training \u2192 evaluation \u2192 deployment. Happy coding!\n Expected Answer: TensorFlow and PyTorch\n Incorrect.\n\n Query 4: Is understanding machine learning foundations important?\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n Model Answer: Yes \u2013 understanding the foundations of machine learning is essential, especially if you want to build a solid, long\u2011term career as a machine\u2011learning engineer.  \n\n### Why the foundations matter\n\n| Foundation | Why it matters |\n|------------|----------------|\n| **Core concepts (bias/variance, cost functions, regularization, error analysis)** | These ideas let you diagnose why a model is under\u2011 or over\u2011fitting, why training stalls, or why a particular dataset is difficult. |\n| **Mathematical tools (linear algebra, calculus, probability, statistics)** | Even when you rely on mature libraries, knowing how the algorithms work helps you pick the right tool, tune hyper\u2011parameters, and avoid pitfalls such as numerical instability or poor convergence. |\n| **Model families (linear regression, logistic regression, decision trees, clustering, neural networks)** | A deep grasp of each family\u2019s assumptions and inductive biases lets you choose the right model for a problem and tweak it effectively. |\n| **Optimization algorithms (gradient descent, momentum, Adam, etc.)** | Understanding how these methods work helps you troubleshoot training dynamics and select appropriate learning rates, batch sizes, or regularizers. |\n| **Architectural insights (CNNs, RNNs, transformers, etc.)** | When a network behaves oddly (e.g., fails on images of a certain resolution), the math behind the architecture gives you clues on how to adjust preprocessing or architecture design. |\n\n### Practical benefits\n\n* **Better debugging** \u2013 When training falters, you can pinpoint whether the issue is with the data, the algorithm, or the implementation.\n* **Informed choices** \u2013 You can evaluate competing libraries or frameworks, knowing which numerical methods they employ and how that might affect accuracy or speed.\n* **Adaptability** \u2013 As new algorithms (like emerging deep\u2011learning architectures) appear, a strong foundation lets you learn them faster.\n* **Communication** \u2013 Explaining model behavior to stakeholders becomes more effective when you can articulate the underlying principles.\n\n### Bottom line\n\nIf you skip the foundational work and dive straight into \u201cplug\u2011and\u2011play\u201d solutions, you\u2019ll likely hit roadblocks that are hard to diagnose and fix. A solid grasp of the math and core concepts gives you the \u201cwhy\u201d behind the \u201chow,\u201d turning you from a tool user into a problem\u2011solving engineer.\n Expected Answer: Yes\n Correct!\n\n Final Manual Evaluation Accuracy: 25.0%\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LLM-Assisted Evaluation"
   ],
   "metadata": {
    "id": "oFgR84kIBUft"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T13:53:12.122425Z",
     "iopub.execute_input": "2025-10-27T13:53:12.123108Z",
     "iopub.status.idle": "2025-10-27T13:53:12.228601Z",
     "shell.execute_reply.started": "2025-10-27T13:53:12.123082Z",
     "shell.execute_reply": "2025-10-27T13:53:12.227817Z"
    },
    "id": "FVSAWLzBBUft"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "y2TXbOYlBUft"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "llm_ev = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    api_key=openai_api_key,\n",
    "\n",
    "\n",
    "example_gen_chain = QAGenerateChain.from_llm(llm_ev)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T14:00:09.873795Z",
     "iopub.execute_input": "2025-10-27T14:00:09.874077Z",
     "iopub.status.idle": "2025-10-27T14:00:09.974428Z",
     "shell.execute_reply.started": "2025-10-27T14:00:09.874057Z",
     "shell.execute_reply": "2025-10-27T14:00:09.973844Z"
    },
    "id": "dgeX4kaWBUfu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")\n",
    "new_examples[0]"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T14:00:12.065149Z",
     "iopub.execute_input": "2025-10-27T14:00:12.065466Z",
     "iopub.status.idle": "2025-10-27T14:00:18.886549Z",
     "shell.execute_reply.started": "2025-10-27T14:00:12.065448Z",
     "shell.execute_reply": "2025-10-27T14:00:18.885676Z"
    },
    "id": "Nj9jblQhBUfu",
    "outputId": "cc0e56bb-6b66-49fb-d448-49d82bc87026"
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_37/3644668000.py:1: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n  new_examples = example_gen_chain.apply_and_parse(\n/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/openai.py:174: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/openai.py:174: UserWarning: Unexpected type for token usage: <class 'float'>\n  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n",
     "output_type": "stream"
    },
    {
     "execution_count": 20,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'qa_pairs': {'query': 'According to the first page of the document, who is identified as the founder associated with the AI career guide, and what is the full title of the guide presented on this page?',\n  'answer': 'The founder identified is the founder of DeepLearning.AI, and the full title of the guide presented on the first page is \u201cHow to Build Your Career in AI \u2013 A Simple Guide,\u201d which is described as \u201cCollected Insights from Andrew Ng.\u201d'}}"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data[0]\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T14:01:01.723242Z",
     "iopub.execute_input": "2025-10-27T14:01:01.723499Z",
     "iopub.status.idle": "2025-10-27T14:01:01.728819Z",
     "shell.execute_reply.started": "2025-10-27T14:01:01.723482Z",
     "shell.execute_reply": "2025-10-27T14:01:01.728136Z"
    },
    "id": "qAsdGwabBUfu",
    "outputId": "e8591189-ead2-48b9-d86c-a22f5b0a89d0"
   },
   "outputs": [
    {
     "execution_count": 21,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': '/kaggle/input/ebook-how-to-build-a-career-in-ai/eBook-How-to-Build-a-Career-in-AI.pdf', 'total_pages': 41, 'page': 0, 'page_label': '1'}, page_content='PAGE 1\\nFounder, DeepLearning.AI\\nCollected Insights\\nfrom Andrew Ng\\nHow to \\nBuild\\nYour\\nCareer\\nin AI\\nA Simple Guide')"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "examples += new_examples\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T14:01:43.699871Z",
     "iopub.execute_input": "2025-10-27T14:01:43.700432Z",
     "iopub.status.idle": "2025-10-27T14:01:43.703692Z",
     "shell.execute_reply.started": "2025-10-27T14:01:43.700406Z",
     "shell.execute_reply": "2025-10-27T14:01:43.702936Z"
    },
    "id": "Lp4JlKtiBUfu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "examples"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T14:01:52.69501Z",
     "iopub.execute_input": "2025-10-27T14:01:52.695368Z",
     "iopub.status.idle": "2025-10-27T14:01:52.70065Z",
     "shell.execute_reply.started": "2025-10-27T14:01:52.695344Z",
     "shell.execute_reply": "2025-10-27T14:01:52.699975Z"
    },
    "id": "bNup74CfBUfu",
    "outputId": "8119332a-1486-4a37-8f74-21746f683c57"
   },
   "outputs": [
    {
     "execution_count": 23,
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'query': 'What is the best way to build a new habit?',\n  'answer': 'Start small and be consistent'},\n {'query': 'Who wrote the book Tiny Habits?', 'answer': 'BJ Fogg'},\n {'query': 'What are the key Python frameworks to learn for AI?',\n  'answer': 'TensorFlow and PyTorch'},\n {'query': 'Is understanding machine learning foundations important?',\n  'answer': 'Yes'},\n {'qa_pairs': {'query': 'According to the first page of the document, who is identified as the founder associated with the AI career guide, and what is the full title of the guide presented on this page?',\n   'answer': 'The founder identified is the founder of DeepLearning.AI, and the full title of the guide presented on the first page is \u201cHow to Build Your Career in AI \u2013 A Simple Guide,\u201d which is described as \u201cCollected Insights from Andrew Ng.\u201d'}},\n {'qa_pairs': {'query': 'According to the document, who is quoted as saying \u201cAI is the new electricity. It will transform and improve all areas of human life,\u201d and what software is listed as the creator of the PDF?',\n   'answer': 'The quote is attributed to Andrew Ng, and the PDF\u2019s creator is listed as \u201cAdobe InDesign 18.0 (Macintosh).\u201d'}},\n {'qa_pairs': {'query': 'According to the Table of Contents shown in the document, what is the title of Chapter 4 and what primary topic does it address?',\n   'answer': 'Chapter 4 is titled **\u201cScoping Successful AI Projects.\u201d** It addresses the primary topic of how to define, plan, and set the boundaries for AI projects to ensure they are viable and aligned with business or research goals.'}},\n {'qa_pairs': {'query': 'According to the passage, how does the author illustrate the practical value of AI and data\u2011science skills for a non\u2011technical profession, and what specific AI technique does he mention that could help a pizza maker improve his business operations?',\n   'answer': 'The author uses the example of a neighborhood pizza maker to show how AI and data\u2011science can benefit a non\u2011technical profession. He explains that, although the pizza maker has little reason to learn how to build a video game or code a website, AI tools can still be highly useful to him. Specifically, the author mentions that a **linear regression model** could help the pizza maker better estimate demand, optimize staffing and supply\u2011chain decisions, and predict sales of items such as Hawaiian pizza, thereby reducing customer wait times and improving overall efficiency.'}},\n {'qa_pairs': {'query': 'According to the document\u2019s metadata, which software (including version and platform) was used to create the PDF, and on what exact date and time (including time zone) was the file originally created?',\n   'answer': 'The PDF was created with **Adobe InDesign 18.0 (Macintosh)**, and the original creation timestamp is **2022-12-13 at 16:08:00\\u202f\u201305:00**.'}}]"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "qa.run(examples[0][\"query\"])\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-27T14:02:08.197772Z",
     "iopub.execute_input": "2025-10-27T14:02:08.198302Z",
     "iopub.status.idle": "2025-10-27T14:02:08.832077Z",
     "shell.execute_reply.started": "2025-10-27T14:02:08.198279Z",
     "shell.execute_reply": "2025-10-27T14:02:08.831494Z"
    },
    "id": "sQ2KkdBXBUfu",
    "outputId": "4d36245d-753d-42a8-c4d9-eafa89ce275a"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n",
     "output_type": "stream"
    },
    {
     "execution_count": 24,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'The advice that appears in the text is that the most effective way to build a new habit is to **start tiny and succeed**.  \\n- **Pick a single, very small action** that you can do with almost zero effort (e.g., one push\u2011up, 10\\u202fseconds of an educational video, a quick stretch).  \\n- **Make it part of a routine cue** so you remember to do it (e.g., right after you brush your teeth).  \\n- **Do it consistently**. The key is to get the action done every day, so the brain creates a reliable cue\u2011action link.  \\n- **Celebrate the tiny win**; noticing that you actually did it reinforces the behavior.  \\n- Once the tiny habit is firmly in place, you can slowly stretch it (e.g., add another push\u2011up or a minute more of study).\\n\\nIn short: **begin with a minuscule, easily achievable step, attach it to a regular cue, and repeat it every day until it becomes automatic.**'"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  }
 ]
}